# ComfyUI - OpenAI Ask (Vision/QA) Node for llama.cpp (MiniCPM-V 4.5)
# Outputs: positive, negative, answer_text, raw_json

import base64
import io
import json
import time
import re
from typing import Any, Dict, List, Optional, Tuple

import requests
from PIL import Image


class OpenAIAskNode:
    """
    é€šè¿‡ OpenAI å…¼å®¹ APIï¼ˆllama.cpp/vLLM ç­‰ï¼‰è¿›è¡Œé—®ç­”/åæ¨æç¤ºè¯ã€‚
    - æ”¯æŒå›¾ç‰‡ -> OpenAI Chat Vision data:URL
    - é»˜è®¤ä¼˜å…ˆç”¨ message.contentï¼ˆå¯é€‰ content_source åˆ‡æ¢ä¸º auto/reasoning_onlyï¼‰
    - è‡ªåŠ¨æ‹†åˆ† Positive/Negativeï¼ˆæ­£å‘è£æ‰ 'Prompt:' ä¹‹å‰æ‰€æœ‰å†…å®¹ï¼›è´Ÿå‘å…¼å®¹å¤šç§æ ‡ç­¾ï¼‰
    - å¦è¾“å‡ºå®Œæ•´æ¸…æ´—åçš„æ–‡æœ¬ä¸åŸå§‹ JSON
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "question": ("STRING", {
                    "multiline": True,
                    "default": "Provide a detailed prompt based on this image. Output exactly two lines:\nPrompt: xxx\nNegative: xxx"
                }),
                "api_base": ("STRING", {
                    "default": "http://127.0.0.1:10000",
                    "tooltip": "llama.cpp serverï¼Œä¾‹å¦‚ï¼šhttp://192.168.1.242:10000ï¼ˆæœ«å°¾ä¸è¦/ï¼‰"
                }),
                "endpoint_path": ("STRING", {
                    "default": "/v1/chat/completions",
                    "tooltip": "llama.cpp é»˜è®¤ä¸º /v1/chat/completions"
                }),
                "model": ("STRING", {
                    "default": "minicpm-v-4.5",
                    "tooltip": "llama.cpp é€šå¸¸å¿½ç•¥æ­¤å­—æ®µï¼Œä½†OpenAIåè®®è¦æ±‚ä¼ ï¼›éšæ„å ä½å³å¯"
                }),
                "temperature": ("FLOAT", {
                    "default": 0.3, "min": 0.0, "max": 2.0, "step": 0.05
                }),
                "top_p": ("FLOAT", {
                    "default": 1.0, "min": 0.0, "max": 1.0, "step": 0.05
                }),
                "max_tokens": ("INT", {
                    "default": 512, "min": 1, "max": 8192, "step": 1
                }),
                "system_prompt": ("STRING", {
                    "multiline": True,
                    "default": (
                        "You are a vision-language assistant. "
                        "Return exactly TWO lines with no extra words:\n"
                        "Prompt: <positive>\nNegative: <negative>"
                    )
                }),
                "use_vision": (["auto", "force_on", "force_off"], {
                    "default": "auto",
                    "tooltip": "auto: æœ‰å›¾å°±å¸¦å›¾ï¼›force_off: çº¯æ–‡æœ¬ï¼›force_on: å³ä½¿æ²¡å›¾ä¹ŸæŒ‰Visionç»“æ„"
                }),
            },
            "optional": {
                # é€‰æ‹©ä»ä½•å¤„å–æ–‡æœ¬
                "content_source": (["content_only", "auto", "reasoning_only"], {
                    "default": "content_only",
                    "tooltip": "content_onlyï¼šåªç”¨ message.contentï¼›autoï¼šcontent ä¼˜å…ˆå¦åˆ™ reasoningï¼›reasoning_onlyï¼šåªç”¨ reasoning_content"
                }),
                "image": ("IMAGE",),
                "api_key": ("STRING", {
                    "multiline": False,
                    "default": "",
                    "tooltip": "llama.cpp é»˜è®¤ä¸æ ¡éªŒï¼Œå¯ç•™ç©º"
                }),
                "extra_headers_json": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "tooltip": "é¢å¤–HTTPå¤´ï¼ˆJSONï¼‰ï¼Œå¦‚ {\"X-My-Header\":\"abc\"}"
                }),
                "timeout_sec": ("INT", {
                    "default": 60, "min": 1, "max": 600, "step": 1
                }),
                # å›¾åƒå‹ç¼©ç›¸å…³
                "max_side": ("INT", {
                    "default": 1280, "min": 256, "max": 4096, "step": 16,
                    "tooltip": "æœ€é•¿è¾¹ç¼©æ”¾åˆ°è¯¥å€¼ï¼ˆç­‰æ¯”ï¼‰ï¼›0 è¡¨ç¤ºä¸ç¼©æ”¾"
                }),
                "image_format": (["JPEG", "PNG"], {
                    "default": "JPEG",
                    "tooltip": "å»ºè®®JPEGä»¥å‡å°ä½“ç§¯ï¼ŒåŠ å¿«æœ¬åœ°ä¼ è¾“"
                }),
                "jpeg_quality": ("INT", {
                    "default": 90, "min": 50, "max": 100, "step": 1,
                    "tooltip": "ä»…åœ¨JPEGæ—¶ç”Ÿæ•ˆ"
                }),
            },
        }

    # Four outputs:
    #   0: positive  1: negative  2: answer_text  3: raw_json
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("positive", "negative", "answer_text", "raw_json")
    FUNCTION = "ask"
    CATEGORY = "ğŸ¥· Integrations/OpenAI"

    # ====== å·¥å…·å‡½æ•° ======
    @staticmethod
    def _resize_keep_aspect(pil: Image.Image, max_side: int) -> Image.Image:
        if max_side is None or max_side <= 0:
            return pil
        w, h = pil.size
        m = max(w, h)
        if m <= max_side:
            return pil
        scale = max_side / float(m)
        new_w = max(1, int(round(w * scale)))
        new_h = max(1, int(round(h * scale)))
        return pil.resize((new_w, new_h), Image.LANCZOS)

    @staticmethod
    def _image_to_data_url(image_tensor, max_side: int, fmt: str, jpeg_quality: int) -> Optional[str]:
        if image_tensor is None:
            return None
        try:
            import numpy as np
            if len(image_tensor.shape) != 4:
                return None
            img = image_tensor[0].cpu().numpy()  # HWC, float32 0..1
            img = (np.clip(img, 0.0, 1.0) * 255).astype("uint8")
            pil = Image.fromarray(img)
            pil = OpenAIAskNode._resize_keep_aspect(pil, max_side)
            buf = io.BytesIO()
            if fmt.upper() == "JPEG":
                pil = pil.convert("RGB")
                pil.save(buf, format="JPEG", quality=int(jpeg_quality), optimize=True)
                mime = "image/jpeg"
            else:
                pil.save(buf, format="PNG")
                mime = "image/png"
            b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
            return f"data:{mime};base64,{b64}"
        except Exception:
            return None

    @staticmethod
    def _build_messages(question: str, system_prompt: str, data_url: Optional[str], use_vision_mode: str):
        user_content: List[Dict[str, Any]] = []
        if question and question.strip():
            user_content.append({"type": "text", "text": question})
        if (use_vision_mode in ("auto", "force_on")) and data_url:
            user_content.append({"type": "image_url", "image_url": {"url": data_url}})
        messages = []
        if system_prompt and system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_content if user_content else question})
        return messages

    @staticmethod
    def _merge_headers(api_key: str, extra_headers_json: str) -> Dict[str, str]:
        headers = {"Content-Type": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
        if extra_headers_json:
            try:
                extra = json.loads(extra_headers_json) or {}
                for k, v in extra.items():
                    headers[k] = v
            except Exception:
                pass
        return headers

    @staticmethod
    def _sanitize_reasoning_text(text: str) -> str:
        """å»æ‰ 'ç”¨æˆ·/User' ä¹‹ç±»çš„å¼€å¤´æ‚é¡¹ï¼ˆä¸ç§»é™¤ä¸­é—´çš„ 'Prompt:'ï¼Œä»¥å…å½±å“åˆ‡åˆ†ï¼‰"""
        if not isinstance(text, str):
            return ""
        t = text.replace("\r\n", "\n")
        t = re.sub(r'^\s*(ç”¨æˆ·|User)\s*[:ï¼š]?\s*\n?', '', t, flags=re.IGNORECASE)
        return t.strip()

    @staticmethod
    def _split_positive_negative(text: str) -> Tuple[str, str]:
        """
        è§„åˆ™ï¼š
        1) è‹¥å‡ºç° â€œPrompt:â€/â€œPositive:â€/â€œæç¤ºè¯:â€/â€œæ­£å‘:â€ ç­‰æ ‡ç­¾ï¼Œ
           åˆ™è£æ‰å…¶ **ä¹‹å‰** çš„æ‰€æœ‰å†…å®¹ï¼ˆåŒ…å«æ ‡ç­¾æœ¬èº«ï¼‰ï¼Œæ ‡ç­¾ä¹‹åè§†ä¸ºæ­£å‘ã€‚
        2) è´Ÿå‘æŒ‰ä»¥ä¸‹æ ‡ç­¾åˆ‡åˆ†ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ï¼š
           Negative Prompt / Negative / Neg / Avoid / Disallow / Do not / è´Ÿå‘ / è´Ÿé¢ / é¿å… / ä¸è¦
        3) è‹¥æœªæ‰¾åˆ°ä»»ä½•è´Ÿå‘æ ‡ç­¾ï¼Œåˆ™è´Ÿå‘ä¸ºç©ºã€‚
        """
        if not text:
            return "", ""

        s = text.replace("\r\n", "\n").strip()

        # 1) è£æ‰ Prompt ä¹‹å‰æ‰€æœ‰å†…å®¹
        prompt_label = re.search(r'(?is)(?:^|\n)\s*(prompt|positive|æç¤ºè¯|æ­£å‘)\s*[:ï¼š]\s*', s)
        if prompt_label:
            s = s[prompt_label.end():].lstrip()

        # 2) å®šä½è´Ÿå‘æ ‡ç­¾å¹¶åˆ‡åˆ†
        neg_re = re.compile(
            r'(?im)\b('
            r'negative\s*prompt|negative|neg|'
            r'avoid|disallow|do\s*not|'
            r'è´Ÿå‘|è´Ÿé¢|é¿å…|ä¸è¦'
            r')\s*[:ï¼š]\s*'
        )
        m = neg_re.search(s)
        if m:
            pos = s[:m.start()].strip()
            neg = s[m.end():].strip()
        else:
            pos, neg = s.strip(), ""

        # 3) å†æ¸…ä¸€æ¬¡æ®‹ç•™æ ‡ç­¾
        pos = re.sub(r'(?im)^\s*(positive|prompt|æç¤ºè¯|æ­£å‘)\s*[:ï¼š]\s*', '', pos).strip()
        neg = re.sub(
            r'(?im)^\s*(negative\s*prompt|negative|neg|avoid|disallow|do\s*not|è´Ÿå‘|è´Ÿé¢|é¿å…|ä¸è¦)\s*[:ï¼š]\s*',
            '',
            neg
        ).strip()

        return pos, neg

    @staticmethod
    def _extract_text_from_content(value: Any) -> str:
        """
        message.content æ—¢å¯èƒ½æ˜¯ stringï¼Œä¹Ÿå¯èƒ½æ˜¯ list[block]ï¼›
        è¿™é‡Œå°½é‡æŠŠé‡Œé¢çš„ text æŠ½å–å‡ºæ¥ã€‚
        """
        if value is None:
            return ""
        if isinstance(value, str):
            return value
        if isinstance(value, list):
            parts: List[str] = []
            for blk in value:
                if isinstance(blk, dict):
                    # OpenAI é£æ ¼ï¼š{"type": "text", "text": "..."} æˆ– {"type":"output_text","text":"..."}
                    t = blk.get("text") or blk.get("content") or ""
                    if isinstance(t, str) and t.strip():
                        parts.append(t)
            return "\n".join(parts).strip()
        # å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬å­—ç¬¦ä¸²
        try:
            return str(value)
        except Exception:
            return ""

    # ====== æ ¸å¿ƒ ======
    def ask(self,
            question: str,
            api_base: str,
            endpoint_path: str,
            model: str,
            temperature: float,
            top_p: float,
            max_tokens: int,
            system_prompt: str,
            use_vision: str,
            content_source: str = "content_only",
            image=None,
            api_key: str = "",
            extra_headers_json: str = "",
            timeout_sec: int = 60,
            max_side: int = 1280,
            image_format: str = "JPEG",
            jpeg_quality: int = 90,
            ) -> Tuple[str, str, str, str]:

        # 1) å¤„ç†å›¾ç‰‡
        data_url = None
        if use_vision != "force_off":
            data_url = self._image_to_data_url(
                image_tensor=image,
                max_side=max_side,
                fmt=image_format,
                jpeg_quality=jpeg_quality
            )

        # 2) Headers
        headers = self._merge_headers(api_key, extra_headers_json)

        # 3) URL
        base = api_base.rstrip("/")
        path = endpoint_path if endpoint_path.startswith("/") else f"/{endpoint_path}"
        url = f"{base}{path}"

        # 4) Payload
        payload = {
            "model": model,
            "messages": self._build_messages(question, system_prompt, data_url, use_vision),
            "temperature": float(temperature),
            "top_p": float(top_p),
            "max_tokens": int(max_tokens),
            "stream": False
        }

        # 5) è¯·æ±‚
        t0 = time.time()
        try:
            resp = requests.post(url, headers=headers, data=json.dumps(payload), timeout=timeout_sec)
        except Exception as e:
            err = f"[OpenAIAsk] request error: {e}"
            return ("", "", err, json.dumps({"error": err}, ensure_ascii=False, indent=2))

        elapsed = f"{(time.time() - t0):.2f}s"

        # 6) è§£æ
        positive = ""
        negative = ""
        answer_text = ""
        raw_json_text = ""
        try:
            data = resp.json()
            raw_json_text = json.dumps(data, ensure_ascii=False, indent=2)

            if resp.status_code >= 400:
                answer_text = f"[OpenAIAsk] HTTP {resp.status_code}: {data}"
            else:
                choices = data.get("choices", [])
                if choices:
                    msg = choices[0].get("message", {}) or {}

                    content   = self._extract_text_from_content(msg.get("content"))
                    reasoning = self._extract_text_from_content(msg.get("reasoning_content"))
                    fallback  = self._extract_text_from_content(choices[0].get("text"))

                    # å…ˆé€‰æºæ–‡æœ¬
                    if content_source == "content_only":
                        out_src = content if content else (fallback or reasoning)
                    elif content_source == "reasoning_only":
                        out_src = reasoning if reasoning else (fallback or content)
                    else:  # auto
                        out_src = content if content else (reasoning if reasoning else fallback)

                    # â€”â€” æ‹†åˆ†æ­£/è´Ÿï¼šåœ¨åŸå§‹ out_src ä¸Šåšï¼ˆé¿å…å…ˆæ¸…æ´—æŠŠ 'Prompt:' åˆ æ‰ï¼‰â€”â€”
                    positive, negative = self._split_positive_negative(out_src)

                    # â€”â€” å®Œæ•´æ–‡æœ¬åšä¸€æ¬¡è½»åº¦æ¸…æ´—ï¼ˆåˆ æ‰å¼€å¤´â€œç”¨æˆ·/Userâ€ç­‰ï¼‰â€”â€”
                    answer_text = self._sanitize_reasoning_text(out_src)

                if not answer_text:
                    answer_text = "[OpenAIAsk] Empty content from server."

                answer_text += f"\n\n[latency: {elapsed}]"

        except Exception as e:
            answer_text = f"[OpenAIAsk] parse error: {e}\nHTTP {resp.status_code} Body: {resp.text}"
            raw_json_text = resp.text

        return (positive, negative, answer_text, raw_json_text)


NODE_CLASS_MAPPINGS = {
    "OpenAIAsk": OpenAIAskNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "OpenAIAsk": "JR Node: OpenAI Ask (Vision/QA)",
}
